{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitnlpconda2e37df55ef7041bb8d56bf0ba20910ea",
   "display_name": "Python 3.7.6 64-bit ('NLP': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델링 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF를 활용한 모델 구현\n",
    "- TF-IDF를 활용해 문장 벡터를 만듬\n",
    "- 입력 값에 대해 TF-IDF 값으로 벡터화를 진행하기 때문에 사이킷런의 TfidfVectorizer를 사용\n",
    "- TfidfVectorizer를 사용하기 위해서는 입력값이 텍스트로 이뤄진 데이터 형태여야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA, header=0, quoting=3)\n",
    "\n",
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF-IDF 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.0, analyzer='char', sublinear_tf=True, ngram_range=(1, 3), max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TfidfVectorizer()\n",
    "- min_df\n",
    "    - 설정한 값 보다 특정 토큰의 df 값이 더 적게 나오면 벡터화 과정에서 제거한다는 의미\n",
    "\n",
    "- analyzer\n",
    "    - 분석하기 위한 기준 단위\n",
    "    - 'word' 와 'char'로 2가지 옵션을 제공함\n",
    "    - 'word'의 경우 단어 하나를 단위로 함\n",
    "    - 'char'의 경우 문자 하나를 단위로 함\n",
    "\n",
    "- sublinear_tf\n",
    "    - 문서의 단어 빈도 수(term frequency)에 대한 스무딩(smoothing) 여부를 설정하는 값\n",
    "\n",
    "- ngram_range\n",
    "    - 빈도의 기본 단위를 어느 범위의 n-gram으로 설정할 것인지를 보는 인자\n",
    "\n",
    "- max_features\n",
    "    - 각 벡터의 최대 길이, 특징의 길이를 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- TfidfVectorizer를 생성한 후 fit_transform 함수를 사용해 전체 문장에 대한 특징 벡터 데이터 X를 생성\n",
    "- TF-IDF로 벡터화한 데이터가 준비 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습데이터와 검증 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 사이킷런 라이브러리에 train_test_split 함수를 활용해 학습 데이터와 검증 데이터를 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "y = np.array(sentiments)\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 입력값인 X와 정답 라벨을 넘파이 배열로 만든 y에 대해 적용해서 학습 데이터와 검증 데이터로 나눔\n",
    "- 비율을 기존 학습 데이터의 20 퍼센트로 설정해 검증 데이터를 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 선언 및 학습\n",
    "- 선형 회귀 모델을 만들기 위해 사이킷런 라이브러리에서 지원하는 LogisticRegression 클래스의 객체를 생성\n",
    "- 이후 이 객체의 fit 함수를 호출하면 데이터에 대한 모델 학습이 진행됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- class_weight\n",
    "    - 'balanced'로 설정해서 각 라벨에 대해 균형 있게 학습할 수 있게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 검증 데이터로 성능 평가\n",
    "- 검증 데이터를 가지고 학습한 모델에 대해 성능을 확인\n",
    "- 성능평가는 앞서 학습한 객체의 score 함수를 이용하여 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy: 0.8598\n"
    }
   ],
   "source": [
    "print(f\"Accuracy: {lgs.score(X_eval, y_eval)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 성능을 평가하는 방법으로는 정확도(Accuracy) 외에도 정밀도(precision), 재현율(recall), f1-score, auc 등 다양한 지표가 있음\n",
    "- 여기서는 간단하게 정확도만 측정함"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Kaggle에 데이터 제출하기\n",
    "- 학습한 모델을 이용하여 평가 데이터 결과를 예측하고 파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리한 텍스트 형태의 평가 데이터 불러오기\n",
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "\n",
    "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>naturally film main themes mortality nostalgia...</td>\n      <td>\"12311_10\"</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>movie disaster within disaster film full great...</td>\n      <td>\"8348_2\"</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>movie kids saw tonight child loved one point k...</td>\n      <td>\"5828_4\"</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>afraid dark left impression several different ...</td>\n      <td>\"7186_2\"</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>accurate depiction small time mob life filmed ...</td>\n      <td>\"12128_7\"</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>sony pictures classics looking sony got rights...</td>\n      <td>\"2155_10\"</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>always felt ms merkerson never gotten role fit...</td>\n      <td>\"59_10\"</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>disappointed movie familiar case read mark fuh...</td>\n      <td>\"2531_1\"</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>opening sequence filled black white shots remi...</td>\n      <td>\"7772_8\"</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>great horror film people want vomit retching g...</td>\n      <td>\"11465_10\"</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                  review          id\n0      naturally film main themes mortality nostalgia...  \"12311_10\"\n1      movie disaster within disaster film full great...    \"8348_2\"\n2      movie kids saw tonight child loved one point k...    \"5828_4\"\n3      afraid dark left impression several different ...    \"7186_2\"\n4      accurate depiction small time mob life filmed ...   \"12128_7\"\n...                                                  ...         ...\n24995  sony pictures classics looking sony got rights...   \"2155_10\"\n24996  always felt ms merkerson never gotten role fit...     \"59_10\"\n24997  disappointed movie familiar case read mark fuh...    \"2531_1\"\n24998  opening sequence filled black white shots remi...    \"7772_8\"\n24999  great horror film people want vomit retching g...  \"11465_10\"\n\n[25000 rows x 2 columns]"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터를 대상으로 이전에 학습 데이터에 대해 사용했던 객체를 사용해 TF_IDF 값으로 벡터화\n",
    "testDataVecs = vectorizer.transform(test_data['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 벡터화할때 평가 데이터에 대해서는 fit을 호출하지 않고 그대로 transform만 호출\n",
    "- fit의 경우 학습 데이터에 맞게 설정했고, 그 설정에 맞게 평가 데이터도 변환하면 됨\n",
    "- 이후 이 값으로 예측한 후 예측값을 하나의 변수로 할당하고 출력해서 형태를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1 0 1 ... 0 1 0]\n"
    }
   ],
   "source": [
    "test_predicted = lgs.predict(testDataVecs)\n",
    "print(test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Kaggle에 제출하기 위해 데이터프레임 형태로 만들어 CSV 파일로 저장\n",
    "- 데이터 형식은 id값과 결과값으로 구성되야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "answer_dataset = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'sentiment': test_predicted\n",
    "})\n",
    "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_tfidf_answer.csv', mode='w', header=True, index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"12311_10\"</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"8348_2\"</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"5828_4\"</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"7186_2\"</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"12128_7\"</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>\"2155_10\"</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>\"59_10\"</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>\"2531_1\"</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>\"7772_8\"</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>\"11465_10\"</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows × 2 columns</p>\n</div>",
      "text/plain": "               id  sentiment\n0      \"12311_10\"          1\n1        \"8348_2\"          0\n2        \"5828_4\"          1\n3        \"7186_2\"          0\n4       \"12128_7\"          1\n...           ...        ...\n24995   \"2155_10\"          1\n24996     \"59_10\"          1\n24997    \"2531_1\"          0\n24998    \"7772_8\"          1\n24999  \"11465_10\"          0\n\n[25000 rows x 2 columns]"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}