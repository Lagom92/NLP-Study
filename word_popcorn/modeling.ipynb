{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitnlpconda2e37df55ef7041bb8d56bf0ba20910ea",
   "display_name": "Python 3.7.6 64-bit ('NLP': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF를 활용한 모델 구현\n",
    "- TF-IDF를 활용해 문장 벡터를 만듬\n",
    "- 입력 값에 대해 TF-IDF 값으로 벡터화를 진행하기 때문에 사이킷런의 TfidfVectorizer를 사용\n",
    "- TfidfVectorizer를 사용하기 위해서는 입력값이 텍스트로 이뤄진 데이터 형태여야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA, header=0, quoting=3)\n",
    "\n",
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.0, analyzer='char', sublinear_tf=True, ngram_range=(1, 3), max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer()\n",
    "- min_df\n",
    "    - 설정한 값 보다 특정 토큰의 df 값이 더 적게 나오면 벡터화 과정에서 제거한다는 의미\n",
    "\n",
    "- analyzer\n",
    "    - 분석하기 위한 기준 단위\n",
    "    - 'word' 와 'char'로 2가지 옵션을 제공함\n",
    "    - 'word'의 경우 단어 하나를 단위로 함\n",
    "    - 'char'의 경우 문자 하나를 단위로 함\n",
    "\n",
    "- sublinear_tf\n",
    "    - 문서의 단어 빈도 수(term frequency)에 대한 스무딩(smoothing) 여부를 설정하는 값\n",
    "\n",
    "- ngram_range\n",
    "    - 빈도의 기본 단위를 어느 범위의 n-gram으로 설정할 것인지를 보는 인자\n",
    "\n",
    "- max_features\n",
    "    - 각 벡터의 최대 길이, 특징의 길이를 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TfidfVectorizer를 생성한 후 fit_transform 함수를 사용해 전체 문장에 대한 특징 벡터 데이터 X를 생성\n",
    "- TF-IDF로 벡터화한 데이터가 준비 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습데이터와 검증 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}